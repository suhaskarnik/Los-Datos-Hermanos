{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shrinkage\n",
    "\n",
    "Fit a Lin.Reg for all *p* predictors. Then shrink the estimated coefficients towards 0 relative to the least square estimates. This is also called *regularization*. This will reduce variance. It may also reduce some coefficients to exactly 0, thereby performing variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use `glmnet` package. The main function is also called `glmnet()`\n",
    "\n",
    "As an input, that function expects:\n",
    "* `x`: a matrix, where each row is an obs vector\n",
    "* `y`: a response variable, quantitative for `family=gaussian|poisson`. For `family=binomial`, it should be either factor with 2 levels or a 2-col matrix of counts (logistical regression)\n",
    "* `family`: as above\n",
    "\n",
    "First clean out the model data of NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'glmnet' was built under R version 3.3.3\"Loading required package: Matrix\n",
      "Loading required package: foreach\n",
      "Warning message:\n",
      "\"package 'foreach' was built under R version 3.3.3\"Loaded glmnet 2.0-5\n",
      "\n",
      "Warning message:\n",
      "\"package 'ISLR' was built under R version 3.3.2\""
     ]
    },
    {
     "data": {
      "text/html": [
       "59"
      ],
      "text/latex": [
       "59"
      ],
      "text/markdown": [
       "59"
      ],
      "text/plain": [
       "[1] 59"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(glmnet)\n",
    "library(ISLR)\n",
    "\n",
    "sum(is.na(Hitters$Salary))  # No. of null Salaries\n",
    "\n",
    "Hitters=na.omit(Hitters)\n",
    "sum(is.na(Hitters$Salary))  # No. of null Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a matrix, remove the first column, which contains the Intercept\n",
    "# We are removing this \n",
    "\n",
    "# model.matrix creates a matrix for the 19 predictors, but it also converts qualitative vars into dummy vars. \n",
    "#   this is important because glmnet can only take quant inputs\n",
    "\n",
    "x=model.matrix(Salary~.,Hitters)[,-1]\n",
    "y=Hitters$Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "Originally, Linear Reg works by reducing the RSS in the training data\n",
    "\n",
    "$$RSS = \\sum_{i=1}^n(y_i - \\hat y_i)^2 = \\sum_{i=1}^n\\bigg(y_i - \\beta_0-\\sum_{j=1}^p\\beta_jx_{ij}\\bigg)^2$$\n",
    "\n",
    "So Linear Reg works by choosing $\\beta_0, \\beta_1,...,\\beta_p$ to minimize the RSS\n",
    "\n",
    "Ridge Regression is similar, it chooses coefficients to minimize:\n",
    "\n",
    "$$RSS + \\lambda\\sum_{j=1}^p\\beta_j^2$$\n",
    "\n",
    "Where $\\lambda \\geq 0$ is a *tuning parameter*. The combined term $\\lambda\\sum_{j=1}^p\\beta_j^2$ is called a *shrinkage penalty*, and it is small when $\\beta_1,...,\\beta_p$ are close to zero, so it effectively shrinks the estimates of $\\beta_j$ towards zero. \n",
    "\n",
    "When $\\lambda=0$, then there is no shrinkage penalty. But as $\\lambda \\rightarrow \\infty$, impact of shrinkage grows, and coefficient estimates approach zero. So of course, selecting a good $\\lambda$ is important.\n",
    "\n",
    "This shrinkage penalty is not applied to $\\beta_0$, which is also why \"0\" doesnt appear in the sum term there. This is because we only want to shrink the est. association of each variable with the response.\n",
    "\n",
    "It is important to apply Ridge Reg only after standardizing the predictors.\n",
    "\n",
    "## The $\\ell_2$ Norm\n",
    "\n",
    "This is a related concept, and is denoted as $||\\beta||_2$, and denoted as \n",
    "$$\\ell_2 = ||\\beta||_2 = \\sqrt{ \\sum_{j=1}^p \\beta_j^2 }$$\n",
    "\n",
    "IOW, $\\ell_2$ is the Mean Square of the coefficient estimates for all coefs except the intercept.\n",
    "\n",
    "As $\\lambda$ increases, the $\\ell_2$ norm will always decrease, and so will $$\\frac{||\\hat{\\beta}_\\lambda^R||_2}{||\\hat{\\beta}||_2}$$\n",
    "\n",
    "Which is a fancy way of saying that as $\\lambda$ increases, the Mean Square of ridge reg coefficients decreases, which is why the ratio of that Mean Square to the Mean Square of the original coefficients.\n",
    "\n",
    "**Note**: In linear algebra, and related areas of mathematics, a norm is a function that assigns a strictly positive length or size to each vector in a vector space\n",
    "\n",
    "\n",
    "### Why does it work?\n",
    "\n",
    "Ridge Reg uses the Bias-Variance trade-off. As $\\lambda$ increases, the flexibility of the regression fit decreases, so variance decreases while bias increases.\n",
    "\n",
    "Hence, it works best when the LM estimates have high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`glmnet()` has an `alpha` arg which determines what type of model is fit. When `alpha=0`, then Ridge Reg is fit, and when `alpha=1` then Lasso is fit. By default, it also standardizes the variables so they are all on the same scale. This can be disabled by setting `standardize=FALSE`.\n",
    "\n",
    "Line 1 below generates a vector called `grid` for $\\lambda$ values. This `grid` contains `100` values ranging from $10^{10}$ to $10^{-2}$. Note: all those values need not be powers of 10.\n",
    "\n",
    "On running `glmnet()`, we get a vector of ridge reg coefficients. Here its a $20\\times100$ matrix, having 20 rows (1 per predictor + intercept) and 100 columns (one for each $\\lambda$ in our `grid`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>20</li>\n",
       "\t<li>100</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 20\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 20\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  20 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid=10^seq(10,-2,length=100)\n",
    "\n",
    "ridge.mod=glmnet(x,y,alpha=0,lambda = grid)\n",
    "\n",
    "dim(coef(ridge.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\lambda$ is high, the coefficients will be much smaller in terms of the $\\ell_2$ norm.\n",
    "\n",
    "Here are the coefs with their $\\ell_2$ norms. Recall that $\\lambda$ was decreasing in `grid`, so the earlier indices have the higher $\\lambda$ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "11497.5699539774"
      ],
      "text/latex": [
       "11497.5699539774"
      ],
      "text/markdown": [
       "11497.5699539774"
      ],
      "text/plain": [
       "[1] 11497.57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "8.01280235943155"
      ],
      "text/latex": [
       "8.01280235943155"
      ],
      "text/markdown": [
       "8.01280235943155"
      ],
      "text/plain": [
       "[1] 8.012802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'=============================='"
      ],
      "text/latex": [
       "'=============================='"
      ],
      "text/markdown": [
       "'=============================='"
      ],
      "text/plain": [
       "[1] \"==============================\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "705.480231071865"
      ],
      "text/latex": [
       "705.480231071865"
      ],
      "text/markdown": [
       "705.480231071865"
      ],
      "text/plain": [
       "[1] 705.4802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "74.0083351028144"
      ],
      "text/latex": [
       "74.0083351028144"
      ],
      "text/markdown": [
       "74.0083351028144"
      ],
      "text/plain": [
       "[1] 74.00834"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "19 x 2 sparse Matrix of class \"dgCMatrix\"\n",
       "                    s49           s59\n",
       "AtBat       0.034769254   0.081799714\n",
       "Hits        0.122605124   0.446785024\n",
       "HmRun       0.603976911   2.153959725\n",
       "Runs        0.215448402   0.764176342\n",
       "RBI         0.239478953   0.814566110\n",
       "Walks       0.341269349   2.000613629\n",
       "Years       0.730504706   0.297974945\n",
       "CAtBat      0.002620416   0.008689379\n",
       "CHits       0.010020385   0.039495960\n",
       "CHmRun      0.065135413   0.188125160\n",
       "CRuns       0.021777011   0.094184999\n",
       "CRBI        0.018047428   0.059413418\n",
       "CWalks      0.024255332   0.091737006\n",
       "LeagueN     2.969861637  26.321442346\n",
       "DivisionW  -6.728152505 -66.126854810\n",
       "PutOuts     0.020970633   0.159095971\n",
       "Assists     0.008757229   0.031901237\n",
       "Errors      0.184599316   0.212203888\n",
       "NewLeagueN  2.990260314  20.033487710"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge.mod$lambda[50]\n",
    "sqrt(sum(coef(ridge.mod)[-1,50]^2))   # ell_2 \n",
    "\n",
    "paste(rep(\"=\",30),collapse = \"\")\n",
    "\n",
    "ridge.mod$lambda[60]\n",
    "sqrt(sum(coef(ridge.mod)[-1,60]^2))   # ell_2\n",
    "\n",
    "coef(ridge.mod)[-1,c(50,60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict()` function can be used to obtain the ridge reg for a new $\\lambda$ value, say `50`. This is done by the `s=50` arg. Not surprisingly the coefs for this low $\\lambda$ value are much higher (in abs terms) than the coefs above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>AtBat</dt>\n",
       "\t\t<dd>-0.358099859376738</dd>\n",
       "\t<dt>Hits</dt>\n",
       "\t\t<dd>1.96935928646357</dd>\n",
       "\t<dt>HmRun</dt>\n",
       "\t\t<dd>-1.27824798145678</dd>\n",
       "\t<dt>Runs</dt>\n",
       "\t\t<dd>1.14589163211962</dd>\n",
       "\t<dt>RBI</dt>\n",
       "\t\t<dd>0.803829228437672</dd>\n",
       "\t<dt>Walks</dt>\n",
       "\t\t<dd>2.71618579623371</dd>\n",
       "\t<dt>Years</dt>\n",
       "\t\t<dd>-6.21831921727865</dd>\n",
       "\t<dt>CAtBat</dt>\n",
       "\t\t<dd>0.00544783719814918</dd>\n",
       "\t<dt>CHits</dt>\n",
       "\t\t<dd>0.10648951402342</dd>\n",
       "\t<dt>CHmRun</dt>\n",
       "\t\t<dd>0.624485956082661</dd>\n",
       "\t<dt>CRuns</dt>\n",
       "\t\t<dd>0.221498463760022</dd>\n",
       "\t<dt>CRBI</dt>\n",
       "\t\t<dd>0.218691380321248</dd>\n",
       "\t<dt>CWalks</dt>\n",
       "\t\t<dd>-0.150024548516927</dd>\n",
       "\t<dt>LeagueN</dt>\n",
       "\t\t<dd>45.9258855144158</dd>\n",
       "\t<dt>DivisionW</dt>\n",
       "\t\t<dd>-118.201136816368</dd>\n",
       "\t<dt>PutOuts</dt>\n",
       "\t\t<dd>0.250232154092559</dd>\n",
       "\t<dt>Assists</dt>\n",
       "\t\t<dd>0.121566461346767</dd>\n",
       "\t<dt>Errors</dt>\n",
       "\t\t<dd>-3.27859954463555</dd>\n",
       "\t<dt>NewLeagueN</dt>\n",
       "\t\t<dd>-9.4966803100264</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[AtBat] -0.358099859376738\n",
       "\\item[Hits] 1.96935928646357\n",
       "\\item[HmRun] -1.27824798145678\n",
       "\\item[Runs] 1.14589163211962\n",
       "\\item[RBI] 0.803829228437672\n",
       "\\item[Walks] 2.71618579623371\n",
       "\\item[Years] -6.21831921727865\n",
       "\\item[CAtBat] 0.00544783719814918\n",
       "\\item[CHits] 0.10648951402342\n",
       "\\item[CHmRun] 0.624485956082661\n",
       "\\item[CRuns] 0.221498463760022\n",
       "\\item[CRBI] 0.218691380321248\n",
       "\\item[CWalks] -0.150024548516927\n",
       "\\item[LeagueN] 45.9258855144158\n",
       "\\item[DivisionW] -118.201136816368\n",
       "\\item[PutOuts] 0.250232154092559\n",
       "\\item[Assists] 0.121566461346767\n",
       "\\item[Errors] -3.27859954463555\n",
       "\\item[NewLeagueN] -9.4966803100264\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "AtBat\n",
       ":   -0.358099859376738Hits\n",
       ":   1.96935928646357HmRun\n",
       ":   -1.27824798145678Runs\n",
       ":   1.14589163211962RBI\n",
       ":   0.803829228437672Walks\n",
       ":   2.71618579623371Years\n",
       ":   -6.21831921727865CAtBat\n",
       ":   0.00544783719814918CHits\n",
       ":   0.10648951402342CHmRun\n",
       ":   0.624485956082661CRuns\n",
       ":   0.221498463760022CRBI\n",
       ":   0.218691380321248CWalks\n",
       ":   -0.150024548516927LeagueN\n",
       ":   45.9258855144158DivisionW\n",
       ":   -118.201136816368PutOuts\n",
       ":   0.250232154092559Assists\n",
       ":   0.121566461346767Errors\n",
       ":   -3.27859954463555NewLeagueN\n",
       ":   -9.4966803100264\n",
       "\n"
      ],
      "text/plain": [
       "        AtBat          Hits         HmRun          Runs           RBI \n",
       "-3.580999e-01  1.969359e+00 -1.278248e+00  1.145892e+00  8.038292e-01 \n",
       "        Walks         Years        CAtBat         CHits        CHmRun \n",
       " 2.716186e+00 -6.218319e+00  5.447837e-03  1.064895e-01  6.244860e-01 \n",
       "        CRuns          CRBI        CWalks       LeagueN     DivisionW \n",
       " 2.214985e-01  2.186914e-01 -1.500245e-01  4.592589e+01 -1.182011e+02 \n",
       "      PutOuts       Assists        Errors    NewLeagueN \n",
       " 2.502322e-01  1.215665e-01 -3.278600e+00 -9.496680e+00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(ridge.mod ,s=50, type =\"coefficients\")[2:20 ,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the samples into a test and train set, and estimate the test error for Ridge Reg\n",
    "\n",
    "Let's try an alternative approach to do the splitting though, just for a change: Randomly choose a subset of numbers between 1 and n. Then this becomes the test set and the rest are training sets. This will split the data 50-50 into test and train - that's what the `nrow(x)/2` is for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "\n",
    "train=sample(1:nrow(x),nrow(x)/2)\n",
    "test=-train\n",
    "y.test=y[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit a ridge reg on the training set, evaluate its MSE on the test set using $\\lambda=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "101036.832669597"
      ],
      "text/latex": [
       "101036.832669597"
      ],
      "text/markdown": [
       "101036.832669597"
      ],
      "text/plain": [
       "[1] 101036.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)\n",
    "ridge.pred=predict(ridge.mod,s=4,newx=x[test,])\n",
    "mean((ridge.pred-y[test])^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So test MSE is 101K. Instead, if we had simply fit a model with just an intercept, we would have predicted each test obs using the mean of the training obs. So, the test MSE in that case would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "193253.113067991"
      ],
      "text/latex": [
       "193253.113067991"
      ],
      "text/markdown": [
       "193253.113067991"
      ],
      "text/plain": [
       "[1] 193253.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean((mean(y[train])-y.test)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same result is also possible if we choose a *very high* value of $\\lambda$ (such as $10^{10}$), as that will drive most coefs to zero or close to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "193253.05679545"
      ],
      "text/latex": [
       "193253.05679545"
      ],
      "text/markdown": [
       "193253.05679545"
      ],
      "text/plain": [
       "[1] 193253.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)\n",
    "ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])\n",
    "mean((ridge.pred-y[test])^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $\\lambda=4$ is definitely better (lower test MSE) than $\\lambda \\rightarrow \\infty$.\n",
    "\n",
    "On the other extreme, $\\lambda=0$ would give a model with the same coefs as vanilla least squares (i.e `lm`). Lets see the test MSE of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "114723.615178307"
      ],
      "text/latex": [
       "114723.615178307"
      ],
      "text/markdown": [
       "114723.615178307"
      ],
      "text/plain": [
       "[1] 114723.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>299.42848754</td><td>299.42883596</td></tr>\n",
       "\t<tr><th scope=row>xAtBat</th><td> -2.54027494</td><td> -2.54014665</td></tr>\n",
       "\t<tr><th scope=row>xHits</th><td>  8.36682108</td><td>  8.36611719</td></tr>\n",
       "\t<tr><th scope=row>xHmRun</th><td> 11.64512445</td><td> 11.64400720</td></tr>\n",
       "\t<tr><th scope=row>xRuns</th><td> -9.09922578</td><td> -9.09877719</td></tr>\n",
       "\t<tr><th scope=row>xRBI</th><td>  2.44104711</td><td>  2.44152119</td></tr>\n",
       "\t<tr><th scope=row>xWalks</th><td>  9.23440293</td><td>  9.23403909</td></tr>\n",
       "\t<tr><th scope=row>xYears</th><td>-22.93673265</td><td>-22.93584442</td></tr>\n",
       "\t<tr><th scope=row>xCAtBat</th><td> -0.18153945</td><td> -0.18160843</td></tr>\n",
       "\t<tr><th scope=row>xCHits</th><td> -0.11598196</td><td> -0.11561496</td></tr>\n",
       "\t<tr><th scope=row>xCHmRun</th><td> -1.33887794</td><td> -1.33836534</td></tr>\n",
       "\t<tr><th scope=row>xCRuns</th><td>  3.32838295</td><td>  3.32817777</td></tr>\n",
       "\t<tr><th scope=row>xCRBI</th><td>  0.07536488</td><td>  0.07511771</td></tr>\n",
       "\t<tr><th scope=row>xCWalks</th><td> -1.07841010</td><td> -1.07828647</td></tr>\n",
       "\t<tr><th scope=row>xLeagueN</th><td> 59.76065162</td><td> 59.76529059</td></tr>\n",
       "\t<tr><th scope=row>xDivisionW</th><td>-98.86233333</td><td>-98.85996590</td></tr>\n",
       "\t<tr><th scope=row>xPutOuts</th><td>  0.34086849</td><td>  0.34086400</td></tr>\n",
       "\t<tr><th scope=row>xAssists</th><td>  0.34164753</td><td>  0.34165605</td></tr>\n",
       "\t<tr><th scope=row>xErrors</th><td> -0.64207160</td><td> -0.64205839</td></tr>\n",
       "\t<tr><th scope=row>xNewLeagueN</th><td> -0.67441589</td><td> -0.67606314</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "\t(Intercept) & 299.42848754 & 299.42883596\\\\\n",
       "\txAtBat &  -2.54027494 &  -2.54014665\\\\\n",
       "\txHits &   8.36682108 &   8.36611719\\\\\n",
       "\txHmRun &  11.64512445 &  11.64400720\\\\\n",
       "\txRuns &  -9.09922578 &  -9.09877719\\\\\n",
       "\txRBI &   2.44104711 &   2.44152119\\\\\n",
       "\txWalks &   9.23440293 &   9.23403909\\\\\n",
       "\txYears & -22.93673265 & -22.93584442\\\\\n",
       "\txCAtBat &  -0.18153945 &  -0.18160843\\\\\n",
       "\txCHits &  -0.11598196 &  -0.11561496\\\\\n",
       "\txCHmRun &  -1.33887794 &  -1.33836534\\\\\n",
       "\txCRuns &   3.32838295 &   3.32817777\\\\\n",
       "\txCRBI &   0.07536488 &   0.07511771\\\\\n",
       "\txCWalks &  -1.07841010 &  -1.07828647\\\\\n",
       "\txLeagueN &  59.76065162 &  59.76529059\\\\\n",
       "\txDivisionW & -98.86233333 & -98.85996590\\\\\n",
       "\txPutOuts &   0.34086849 &   0.34086400\\\\\n",
       "\txAssists &   0.34164753 &   0.34165605\\\\\n",
       "\txErrors &  -0.64207160 &  -0.64205839\\\\\n",
       "\txNewLeagueN &  -0.67441589 &  -0.67606314\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| (Intercept) | 299.42848754 | 299.42883596 | \n",
       "| xAtBat |  -2.54027494 |  -2.54014665 | \n",
       "| xHits |   8.36682108 |   8.36611719 | \n",
       "| xHmRun |  11.64512445 |  11.64400720 | \n",
       "| xRuns |  -9.09922578 |  -9.09877719 | \n",
       "| xRBI |   2.44104711 |   2.44152119 | \n",
       "| xWalks |   9.23440293 |   9.23403909 | \n",
       "| xYears | -22.93673265 | -22.93584442 | \n",
       "| xCAtBat |  -0.18153945 |  -0.18160843 | \n",
       "| xCHits |  -0.11598196 |  -0.11561496 | \n",
       "| xCHmRun |  -1.33887794 |  -1.33836534 | \n",
       "| xCRuns |   3.32838295 |   3.32817777 | \n",
       "| xCRBI |   0.07536488 |   0.07511771 | \n",
       "| xCWalks |  -1.07841010 |  -1.07828647 | \n",
       "| xLeagueN |  59.76065162 |  59.76529059 | \n",
       "| xDivisionW | -98.86233333 | -98.85996590 | \n",
       "| xPutOuts |   0.34086849 |   0.34086400 | \n",
       "| xAssists |   0.34164753 |   0.34165605 | \n",
       "| xErrors |  -0.64207160 |  -0.64205839 | \n",
       "| xNewLeagueN |  -0.67441589 |  -0.67606314 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "            [,1]         [,2]        \n",
       "(Intercept) 299.42848754 299.42883596\n",
       "xAtBat       -2.54027494  -2.54014665\n",
       "xHits         8.36682108   8.36611719\n",
       "xHmRun       11.64512445  11.64400720\n",
       "xRuns        -9.09922578  -9.09877719\n",
       "xRBI          2.44104711   2.44152119\n",
       "xWalks        9.23440293   9.23403909\n",
       "xYears      -22.93673265 -22.93584442\n",
       "xCAtBat      -0.18153945  -0.18160843\n",
       "xCHits       -0.11598196  -0.11561496\n",
       "xCHmRun      -1.33887794  -1.33836534\n",
       "xCRuns        3.32838295   3.32817777\n",
       "xCRBI         0.07536488   0.07511771\n",
       "xCWalks      -1.07841010  -1.07828647\n",
       "xLeagueN     59.76065162  59.76529059\n",
       "xDivisionW  -98.86233333 -98.85996590\n",
       "xPutOuts      0.34086849   0.34086400\n",
       "xAssists      0.34164753   0.34165605\n",
       "xErrors      -0.64207160  -0.64205839\n",
       "xNewLeagueN  -0.67441589  -0.67606314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid,thresh=1e-12)\n",
    "ridge.pred=predict(ridge.mod,s=0,newx=x[test,])\n",
    "mean((ridge.pred-y[test])^2)\n",
    "\n",
    "cbind(\n",
    "lm(y~x,subset=train)$coefficients,\n",
    "predict(ridge.mod,s=0,exact=T,type=\"coefficients\")[1:20,]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But choosing $\\lambda$ arbitrarily is not good practice. Let's use X-validation for this instead. There's a `cv.glmnet()` function that can do this for us. By default it does 10-fold X-validation, but that can be tweaked by using the `nfolds` arg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "211.741584781282"
      ],
      "text/latex": [
       "211.741584781282"
      ],
      "text/markdown": [
       "211.741584781282"
      ],
      "text/plain": [
       "[1] 211.7416"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "96015.5127255327"
      ],
      "text/latex": [
       "96015.5127255327"
      ],
      "text/markdown": [
       "96015.5127255327"
      ],
      "text/plain": [
       "[1] 96015.51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "\n",
    "cv.out=cv.glmnet(x[train,],y[train],alpha=0)\n",
    "plot(cv.out)\n",
    "\n",
    "bestlambda=cv.out$lambda.min\n",
    "bestlambda\n",
    "\n",
    "ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])\n",
    "mean((ridge.pred-y[test])^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Test MSE for the cross-validated $\\lambda$ ridge reg is **96015**, while the one with the $\\lambda=4$ was **101036**. That is an improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>9.88487156523819</dd>\n",
       "\t<dt>AtBat</dt>\n",
       "\t\t<dd>0.0314399123075993</dd>\n",
       "\t<dt>Hits</dt>\n",
       "\t\t<dd>1.00882875071523</dd>\n",
       "\t<dt>HmRun</dt>\n",
       "\t\t<dd>0.139276236015288</dd>\n",
       "\t<dt>Runs</dt>\n",
       "\t\t<dd>1.11320780992504</dd>\n",
       "\t<dt>RBI</dt>\n",
       "\t\t<dd>0.873189900643772</dd>\n",
       "\t<dt>Walks</dt>\n",
       "\t\t<dd>1.80410229199678</dd>\n",
       "\t<dt>Years</dt>\n",
       "\t\t<dd>0.130743811114436</dd>\n",
       "\t<dt>CAtBat</dt>\n",
       "\t\t<dd>0.0111397797786966</dd>\n",
       "\t<dt>CHits</dt>\n",
       "\t\t<dd>0.0648984331610168</dd>\n",
       "\t<dt>CHmRun</dt>\n",
       "\t\t<dd>0.451585462080598</dd>\n",
       "\t<dt>CRuns</dt>\n",
       "\t\t<dd>0.12900049045775</dd>\n",
       "\t<dt>CRBI</dt>\n",
       "\t\t<dd>0.13737711633305</dd>\n",
       "\t<dt>CWalks</dt>\n",
       "\t\t<dd>0.0290857160383186</dd>\n",
       "\t<dt>LeagueN</dt>\n",
       "\t\t<dd>27.1822753486268</dd>\n",
       "\t<dt>DivisionW</dt>\n",
       "\t\t<dd>-91.6341129943135</dd>\n",
       "\t<dt>PutOuts</dt>\n",
       "\t\t<dd>0.191492519898057</dd>\n",
       "\t<dt>Assists</dt>\n",
       "\t\t<dd>0.0425453623726451</dd>\n",
       "\t<dt>Errors</dt>\n",
       "\t\t<dd>-1.81244470270312</dd>\n",
       "\t<dt>NewLeagueN</dt>\n",
       "\t\t<dd>7.2120838996523</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 9.88487156523819\n",
       "\\item[AtBat] 0.0314399123075993\n",
       "\\item[Hits] 1.00882875071523\n",
       "\\item[HmRun] 0.139276236015288\n",
       "\\item[Runs] 1.11320780992504\n",
       "\\item[RBI] 0.873189900643772\n",
       "\\item[Walks] 1.80410229199678\n",
       "\\item[Years] 0.130743811114436\n",
       "\\item[CAtBat] 0.0111397797786966\n",
       "\\item[CHits] 0.0648984331610168\n",
       "\\item[CHmRun] 0.451585462080598\n",
       "\\item[CRuns] 0.12900049045775\n",
       "\\item[CRBI] 0.13737711633305\n",
       "\\item[CWalks] 0.0290857160383186\n",
       "\\item[LeagueN] 27.1822753486268\n",
       "\\item[DivisionW] -91.6341129943135\n",
       "\\item[PutOuts] 0.191492519898057\n",
       "\\item[Assists] 0.0425453623726451\n",
       "\\item[Errors] -1.81244470270312\n",
       "\\item[NewLeagueN] 7.2120838996523\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   9.88487156523819AtBat\n",
       ":   0.0314399123075993Hits\n",
       ":   1.00882875071523HmRun\n",
       ":   0.139276236015288Runs\n",
       ":   1.11320780992504RBI\n",
       ":   0.873189900643772Walks\n",
       ":   1.80410229199678Years\n",
       ":   0.130743811114436CAtBat\n",
       ":   0.0111397797786966CHits\n",
       ":   0.0648984331610168CHmRun\n",
       ":   0.451585462080598CRuns\n",
       ":   0.12900049045775CRBI\n",
       ":   0.13737711633305CWalks\n",
       ":   0.0290857160383186LeagueN\n",
       ":   27.1822753486268DivisionW\n",
       ":   -91.6341129943135PutOuts\n",
       ":   0.191492519898057Assists\n",
       ":   0.0425453623726451Errors\n",
       ":   -1.81244470270312NewLeagueN\n",
       ":   7.2120838996523\n",
       "\n"
      ],
      "text/plain": [
       " (Intercept)        AtBat         Hits        HmRun         Runs          RBI \n",
       "  9.88487157   0.03143991   1.00882875   0.13927624   1.11320781   0.87318990 \n",
       "       Walks        Years       CAtBat        CHits       CHmRun        CRuns \n",
       "  1.80410229   0.13074381   0.01113978   0.06489843   0.45158546   0.12900049 \n",
       "        CRBI       CWalks      LeagueN    DivisionW      PutOuts      Assists \n",
       "  0.13737712   0.02908572  27.18227535 -91.63411299   0.19149252   0.04254536 \n",
       "      Errors   NewLeagueN \n",
       " -1.81244470   7.21208390 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out=glmnet(x,y,alpha=0)\n",
    "predict(out,type=\"coefficients\",s=bestlambda)[1:20,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the coefs are zero, as Ridge Reg doesn't eliminate variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso\n",
    "\n",
    "However, Ridge Reg has a disadvantage: it will contain all *p* predictors. It may shrink some of them to almost (but not exactly) zero. This doesn't affect accuracy, but reduces interpretability and makes the model harder to explain.\n",
    "\n",
    "*Lasso coefficients* try to minimize the quantity:\n",
    "\n",
    "$$ \\begin{equation} \\sum_{i=1}^n\\bigg( y_i - \\beta_0-\\sum_{j=1}^p\\beta_jx_{ij} \\bigg)^2 + \\lambda\\sum_{j=1}^p |\\beta_j| = RSS + \\lambda\\sum_{j=1}^p |\\beta_j| \\end{equation}$$\n",
    "\n",
    "This also shrinks the coefficient estimates towards zero. But it has the effect of making some coefficients *exactly* zero. This is also known as a *sparse* model - one that contains a subset of predictors.\n",
    "\n",
    "\n",
    "\n",
    "In contrast to Ridge Reg's $\\ell_2$ penalty, Lasso applies an $\\ell_1$ penalty. This is expressed as:\n",
    "$$\\ell_1 = \\mid\\mid\\beta\\mid\\mid_1 = \\sum_{j=1}^p \\mid \\beta_j \\mid$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAP1BMVEUAAAAAAP8AzQAA//9N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\nCRBASIAAQgIEEBIggJAAAf8P6insbHa+ODcAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)\n",
    "plot(lasso.mod,xvar=\"lambda\",label=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows how variables \"enter the model\" as Lambda changes. When $log(\\lambda)=0$, all coefficients are present. But as it increases, variables start shrinking to zero. At about $log(\\lambda)=3$, only three variables, the ones represented by the green, pink and cyan lines. \n",
    "\n",
    "Let's perform X-validation and compute the test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "100743.446221539"
      ],
      "text/latex": [
       "100743.446221539"
      ],
      "text/markdown": [
       "100743.446221539"
      ],
      "text/plain": [
       "[1] 100743.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nAAEQCUCA/wF8a9Ic9608SQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "cv.out=cv.glmnet(x[train,],y[train],alpha=1)\n",
    "plot(cv.out)\n",
    "bestlam=cv.out$lambda.min\n",
    "\n",
    "lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])\n",
    "mean((lasso.pred-y[test])^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE is similar to (though a little higher than) the MSE of the Ridge Reg. But it reduces some of the coefs to zero, performing variable elimination.\n",
    "\n",
    "See below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>18.5394843700404</dd>\n",
       "\t<dt>AtBat</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Hits</dt>\n",
       "\t\t<dd>1.87353897868797</dd>\n",
       "\t<dt>HmRun</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Runs</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>RBI</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Walks</dt>\n",
       "\t\t<dd>2.21784439442808</dd>\n",
       "\t<dt>Years</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>CAtBat</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>CHits</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>CHmRun</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>CRuns</dt>\n",
       "\t\t<dd>0.207125172948793</dd>\n",
       "\t<dt>CRBI</dt>\n",
       "\t\t<dd>0.413013208899728</dd>\n",
       "\t<dt>CWalks</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>LeagueN</dt>\n",
       "\t\t<dd>3.26666772880497</dd>\n",
       "\t<dt>DivisionW</dt>\n",
       "\t\t<dd>-103.484545814138</dd>\n",
       "\t<dt>PutOuts</dt>\n",
       "\t\t<dd>0.220428413476128</dd>\n",
       "\t<dt>Assists</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>Errors</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>NewLeagueN</dt>\n",
       "\t\t<dd>0</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 18.5394843700404\n",
       "\\item[AtBat] 0\n",
       "\\item[Hits] 1.87353897868797\n",
       "\\item[HmRun] 0\n",
       "\\item[Runs] 0\n",
       "\\item[RBI] 0\n",
       "\\item[Walks] 2.21784439442808\n",
       "\\item[Years] 0\n",
       "\\item[CAtBat] 0\n",
       "\\item[CHits] 0\n",
       "\\item[CHmRun] 0\n",
       "\\item[CRuns] 0.207125172948793\n",
       "\\item[CRBI] 0.413013208899728\n",
       "\\item[CWalks] 0\n",
       "\\item[LeagueN] 3.26666772880497\n",
       "\\item[DivisionW] -103.484545814138\n",
       "\\item[PutOuts] 0.220428413476128\n",
       "\\item[Assists] 0\n",
       "\\item[Errors] 0\n",
       "\\item[NewLeagueN] 0\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   18.5394843700404AtBat\n",
       ":   0Hits\n",
       ":   1.87353897868797HmRun\n",
       ":   0Runs\n",
       ":   0RBI\n",
       ":   0Walks\n",
       ":   2.21784439442808Years\n",
       ":   0CAtBat\n",
       ":   0CHits\n",
       ":   0CHmRun\n",
       ":   0CRuns\n",
       ":   0.207125172948793CRBI\n",
       ":   0.413013208899728CWalks\n",
       ":   0LeagueN\n",
       ":   3.26666772880497DivisionW\n",
       ":   -103.484545814138PutOuts\n",
       ":   0.220428413476128Assists\n",
       ":   0Errors\n",
       ":   0NewLeagueN\n",
       ":   0\n",
       "\n"
      ],
      "text/plain": [
       " (Intercept)        AtBat         Hits        HmRun         Runs          RBI \n",
       "  18.5394844    0.0000000    1.8735390    0.0000000    0.0000000    0.0000000 \n",
       "       Walks        Years       CAtBat        CHits       CHmRun        CRuns \n",
       "   2.2178444    0.0000000    0.0000000    0.0000000    0.0000000    0.2071252 \n",
       "        CRBI       CWalks      LeagueN    DivisionW      PutOuts      Assists \n",
       "   0.4130132    0.0000000    3.2666677 -103.4845458    0.2204284    0.0000000 \n",
       "      Errors   NewLeagueN \n",
       "   0.0000000    0.0000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out=glmnet(x,y,alpha=1,lambda=grid)\n",
    "lasso.coef=predict(out,type=\"coefficients\",s=bestlam)[1:20,]\n",
    "lasso.coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've turned 12 variables to zero, thereby reducing our variables to just 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "Lasso works better when the number of *true* predictors are relatively smaller. In practice, it is better to use cross-validation to identify whether Lasso or Ridge Reg is better for a specific model.\n",
    "\n",
    "\n",
    "### Selecting the tuning parameter\n",
    "\n",
    "Create a grid of $\\lambda$ values, compute the cross-validation error for them. Then select the one which has the lowest X-validation error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
